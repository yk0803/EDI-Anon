{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from true_classify import *\n",
    "from Utils import *\n",
    "from anonymization_methods import *\n",
    "from datasets import *\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import Counter\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d283082",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing data directories\n",
    "source_path = 'D:/Younas_Work/D2_Final/Original/All FR/train'\n",
    "\n",
    "class_names = [folder for folder in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, folder))]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "file_list = os.listdir(source_path)\n",
    "model_dir = 'Convnext_pretrained_younas.pt'\n",
    "\n",
    "output_path = 'D:/Younas_Work/D2_Final/Anonymized/Expite/Simple_Pix_Old_15/Face_Recognition'\n",
    "\n",
    "save_roc_dir = 'D:/Younas_Work/D2_Final/Results_Final/ROC/ROC Plots Mouth_Masked/'\n",
    "excel_file_path = 'D:/Younas_Work/D2_Final/Results_Final/Excel_Sheets/Mouth_Masked.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a64045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.convnext_base(pretrained=True)\n",
    "model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('Convnext_pretrained_younas.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will try a fixed q in each iteration\n",
    "q=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50893a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Parameter values\n",
    "\n",
    "# we will put all the values to highest possible to minimize the changes.\n",
    "\n",
    "#For Simple Blur\n",
    "blur_kernel_size = 3\n",
    "\n",
    "#For DP Blur\n",
    "#block\n",
    "b = 16\n",
    "#m & eps are for privacy budget. Larger m = more noise\n",
    "m = 2\n",
    "#eps is the privacy parameter in DP, smaller eps means higher noise and more distortion\n",
    "eps = 100\n",
    "#K is kernel size for gaussian blur. Height and width of the Gaussian kernel\n",
    "k = 9\n",
    "#SD of Gaussian blur. Larger sigma means more blurring\n",
    "sigma = 0\n",
    "\n",
    "#For Simple Pixelate\n",
    "pixel_size = 3\n",
    "\n",
    "\n",
    "#For DP Pixelate\n",
    "#b, m and eps are the same for DP pixelate and DP Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_batch_size = 1\n",
    "# our_test_loader = create_test_loader(source_path, new_batch_size)\n",
    "# final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "# prev_acc = final_acc\n",
    "# prev_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, dataset_name, save_dir):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "\n",
    "    # Plot macro-average ROC curve\n",
    "    plt.plot(fpr['micro'], tpr['micro'], color='deeppink', linestyle=':', lw=lw,\n",
    "             label='Macro-average ROC curve (area = {0:0.2f})'.format(roc_auc['micro']))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC for ' + dataset_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, f'ROC_{dataset_name}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e962d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, f1_score, auc, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import xlrd\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "def test_images_classification(original_model, device, local_test_loader, excel_file_path, save_roc_dir):\n",
    "    original_model.eval()\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    correct_examples = []\n",
    "    logits = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    \n",
    "    excel_dir = os.path.dirname(excel_file_path)\n",
    "\n",
    "    # Extract the dataset name from the complete path of local_test_loader\n",
    "    dataset_name = os.path.basename(local_test_loader.dataset.root)\n",
    "\n",
    "    # Extract the complete path of local_test_loader\n",
    "    complete_path = local_test_loader.dataset.root\n",
    "\n",
    "    # Loop over all examples in the test set\n",
    "    for data, target in tqdm(local_test_loader):\n",
    "        counter += 1\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        with torch.no_grad():\n",
    "            output = original_model(data)\n",
    "\n",
    "        final_pred = torch.argmax(output, dim=1)\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "        correct_examples.append(data)\n",
    "        labels.append(target)\n",
    "        logits.append(output)\n",
    "    final_acc = correct / float(len(local_test_loader))\n",
    "\n",
    "    # Calculate the F1 score, precision, and recall\n",
    "    all_logits = torch.cat(logits, dim=0)\n",
    "    all_labels = torch.cat(labels, dim=0)\n",
    "    predicted_labels = torch.argmax(all_logits, dim=1)\n",
    "    f1 = f1_score(all_labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "    precision = precision_score(all_labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "    recall = recall_score(all_labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "\n",
    "    # Calculate and save the ROC curve data\n",
    "    all_probs = torch.nn.functional.softmax(all_logits, dim=1)\n",
    "    num_classes = all_probs.shape[1]\n",
    "    one_hot_labels = torch.zeros_like(all_probs).scatter_(1, all_labels.view(-1, 1), 1)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(one_hot_labels[:, i].cpu(), all_probs[:, i].cpu())\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Micro-average ROC curve and AUC\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(one_hot_labels.cpu().ravel(), all_probs.cpu().ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Save summary to Excel\n",
    "    if os.path.exists(excel_file_path):\n",
    "        df_summary = pd.read_excel(excel_file_path, sheet_name=\"Summary\", engine=\"openpyxl\")\n",
    "        new_row = {\"Complete Path\": complete_path, \"Accuracy\": final_acc, \"F1 Score\": f1, \"Precision\": precision, \"Recall\": recall, \"AUC\": roc_auc[\"micro\"]}\n",
    "        df_summary = df_summary.append(new_row, ignore_index=True)\n",
    "        df_summary.to_excel(excel_file_path, sheet_name=\"Summary\", index=False)\n",
    "    else:\n",
    "        summary_data = {\"Complete Path\": [complete_path], \"Accuracy\": [final_acc], \"F1 Score\": [f1], \"Precision\": [precision], \"Recall\": [recall], \"AUC\": [roc_auc[\"micro\"]]}\n",
    "        df_summary = pd.DataFrame(summary_data)\n",
    "        df_summary.to_excel(excel_file_path, sheet_name=\"Summary\", index=False)\n",
    "    \n",
    "    # Plot and save the ROC curve\n",
    "    plot_roc_curve(fpr, tpr, roc_auc, dataset_name, save_roc_dir)\n",
    "\n",
    "    # Return the accuracy, F1 score, and an adversarial example\n",
    "    return final_acc, correct_examples, labels, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4baab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = 'D:/Younas_Work/SOTA/DP/'\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time : {overall_execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train\n",
    "\n",
    "100\n",
    "\n",
    "961\n",
    "\n",
    "\n",
    "91.44109797941289\n",
    "\n",
    "Overall execution time : 18709.195513010025 seconds\n",
    "    \n",
    "\n",
    "test\n",
    "72.36421725239617\n",
    "\n",
    "Overall execution time : 879.967887878418 seconds\n",
    "    \n",
    "68.97590361445783\n",
    "\n",
    "Overall execution time : 236.98045086860657 seconds\n",
    "    \n",
    "    \n",
    "Val\n",
    "    \n",
    "68.97590361445783\n",
    "\n",
    "Overall execution time : 236.98045086860657 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "24.05789186237029\n",
    "\n",
    "Overall execution time : 4703.626936912537 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'D:/Younas_Work/D2_Final/Anonymized/Original/Simple_Pix/BS_25/Face_Recognition'\n",
    "# Acc: 24.05789186237029\n",
    "# Time: 2209.5845515727997 seconds\n",
    "    \n",
    "# 'D:/Younas_Work/D2_Final/Anonymized/Original/Simple_Pix/BS_50/Face_Recognition'\n",
    "# Acc: 2.3211359912616056\n",
    "# Time: 3743.299655675888 seconds\n",
    "    \n",
    "# 'D:/Younas_Work/D2_Final/Anonymized/Original/Simple_Pix/BS_75/Face_Recognition'\n",
    "# Acc:\n",
    "# Time: \n",
    "\n",
    "# 'D:/Younas_Work/D2_Final/Anonymized/Original/Simple_Pix/BS_100/Face_Recognition'\n",
    "# Acc:\n",
    "# Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489af996",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = 'D:/Younas_Work/D2_Final/Anonymized/Expite/Simple_Pix_Old_15/Face_Recognition/Iteration_15'\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "end_time = time.time()\n",
    "acc_time = end_time - start_time\n",
    "print(f\"\\nAcc execution time: {acc_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for itera in range(16,17):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "\n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "\n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "\n",
    "        # Create subfolder based on the class name\n",
    "    #         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "\n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "\n",
    "\n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "    # Call different perturbation functions here\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "            perturbed = create_pixelated_image(x, pixel_size)\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#            perturbed = create_dp_pixelated_image(x, b, m, eps)\n",
    "\n",
    "\n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "\n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "\n",
    "end_time = time.time()\n",
    "Anon_execution_time = end_time - start_time\n",
    "print(f\"\\nAnon Time: {Anon_execution_time} seconds\")\n",
    "print(f\"All images processed for iteration number {itera}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a656a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "patience = 5\n",
    "\n",
    "for itera in range(1,2):\n",
    "\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "\n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "\n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "\n",
    "        # Create subfolder based on the class name\n",
    "    #         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "\n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "\n",
    "\n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "    # Call different perturbation functions here\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "    #             perturbed = create_pixelated_image(x, pixel_size)\n",
    "    #             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "            perturbed = create_dp_pixelated_image(x, b, m, eps)\n",
    "\n",
    "\n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "\n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    \n",
    "    new_test_path = iteration_out_path\n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    iter_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "    print(f\"The accuracy after iteration {itera} is {iter_acc*100}%\")\n",
    "    \n",
    "    if (iter_acc > prev_acc):\n",
    "        patience -= 1\n",
    "        prev_acc = iter_acc\n",
    "        print(\"No Drop\")\n",
    "        if patience == 0:\n",
    "            break\n",
    "    else:\n",
    "        prev_acc = iter_acc\n",
    "        patience = 5\n",
    "        \n",
    "    if (iter_acc < .01):\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time: {overall_execution_time} seconds\")\n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39631c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebb4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585ea3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab0364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6f42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162fd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/Iteration_4/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, \"EDI_Simple_Blur.xlsx\")\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time: {overall_execution_time} seconds\")\n",
    "\n",
    "start_time2 = time.time()\n",
    "\n",
    "\n",
    "patience = 5\n",
    "for itera in range(5,10):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "        \n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "        \n",
    "        # Create subfolder based on the class name\n",
    "#         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "            \n",
    "            \n",
    "            # Call different perturbation functions here\n",
    "            perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "#            perturbed = create_pixelated_image(x, pixel_size)\n",
    "#            perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#            perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "    \n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "        \n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    \n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    iter_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, \"EDI_Simple_Blur.xlsx\")\n",
    "    print(f\"The accuracy after iteration {itera} is {iter_acc*100}%\")\n",
    "    \n",
    "    if (iter_acc > prev_acc):\n",
    "        patience -= 1\n",
    "        prev_acc = iter_acc\n",
    "        print(\"No Drop\")\n",
    "        if patience == 0:\n",
    "            break\n",
    "    else:\n",
    "        prev_acc = iter_acc\n",
    "        patience = 5\n",
    "        \n",
    "    if (iter_acc < .01):\n",
    "        break\n",
    "\n",
    "end_time2 = time.time()\n",
    "overall_execution_time2 = end_time2 - start_time2\n",
    "print(f\"\\nOverall execution time: {overall_execution_time2} seconds\")\n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034edb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b33a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fad8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/Iteration_9/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "\n",
    "patience = 5\n",
    "for itera in range(10,15):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "        \n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "        \n",
    "        # Create subfolder based on the class name\n",
    "#         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "            \n",
    "            # Call different perturbation functions here\n",
    "#             perturbed = create_pixelated_image(x, pixel_size)\n",
    "\n",
    "#            perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "            perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "    \n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "        \n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    \n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    iter_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after iteration {itera} is {iter_acc*100}%\")\n",
    "    \n",
    "    if (iter_acc > prev_acc):\n",
    "        patience -= 1\n",
    "        prev_acc = iter_acc\n",
    "        print(\"No Drop\")\n",
    "        if patience == 0:\n",
    "            break\n",
    "    else:\n",
    "        prev_acc = iter_acc\n",
    "        patience = 5\n",
    "        \n",
    "    if (iter_acc < .01):\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time: {overall_execution_time} seconds\")\n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa28beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/Iteration_14/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "\n",
    "patience = 5\n",
    "for itera in range(15,20):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "        \n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "        \n",
    "        # Create subfolder based on the class name\n",
    "#         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "            \n",
    "            # Call different perturbation functions here\n",
    "            perturbed = create_pixelated_image(x, pixel_size)\n",
    "\n",
    "#            perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "    \n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "        \n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    \n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    iter_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after iteration {itera} is {iter_acc*100}%\")\n",
    "    \n",
    "    if (iter_acc > prev_acc):\n",
    "        patience -= 1\n",
    "        prev_acc = iter_acc\n",
    "        print(\"No Drop\")\n",
    "        if patience == 0:\n",
    "            break\n",
    "    else:\n",
    "        prev_acc = iter_acc\n",
    "        patience = 5\n",
    "        \n",
    "    if (iter_acc < .01):\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time: {overall_execution_time} seconds\")\n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9685e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ab5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/Iteration_14/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "\n",
    "patience = 5\n",
    "for itera in range(15,20):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "        \n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "        \n",
    "        # Create subfolder based on the class name\n",
    "#         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "            # Call different perturbation functions here\n",
    "\n",
    "#             perturbed = create_dp_pixelated_image(x, b, m, eps)\n",
    "            perturbed = create_pixelated_image(x, pixel_size)\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "    \n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "        \n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    \n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    iter_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after iteration {itera} is {iter_acc*100}%\")\n",
    "    \n",
    "    if (iter_acc > prev_acc):\n",
    "        patience -= 1\n",
    "        prev_acc = iter_acc\n",
    "        print(\"No Drop\")\n",
    "        if patience == 0:\n",
    "            break\n",
    "    else:\n",
    "        prev_acc = iter_acc\n",
    "        patience = 5\n",
    "        \n",
    "    if (iter_acc < .01):\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time: {overall_execution_time} seconds\")\n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aea01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/Iteration_18/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "prev_acc = final_acc\n",
    "\n",
    "\n",
    "# Loop until all quantile values have been processed\n",
    "patience = 5\n",
    "for itera in range(19,20):\n",
    "\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "        # Create subfolder based on the class name\n",
    "        class_subfolder = class_names[correct_label.item()]\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(class_output_path):\n",
    "            os.makedirs(class_output_path)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "            # Call different perturbation functions here\n",
    "\n",
    "            perturbed = create_dp_pixelated_image(x, b, m, eps)\n",
    "#             perturbed = create_pixelated_image(x, pixel_size)\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "    \n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, q)\n",
    "        \n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    \n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    iter_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after iteration {itera} is {iter_acc*100}%\")\n",
    "    \n",
    "    if (iter_acc > prev_acc):\n",
    "        patience -= 1\n",
    "        prev_acc = iter_acc\n",
    "        print(\"No Drop\")\n",
    "        if patience == 0:\n",
    "            break\n",
    "    else:\n",
    "        prev_acc = iter_acc\n",
    "        patience = 5\n",
    "end_time = time.time()\n",
    "overall_execution_time = end_time - start_time\n",
    "print(f\"\\nOverall execution time: {overall_execution_time} seconds\")\n",
    "\n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/iteration_9\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1231105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "for itera in range(10,15):\n",
    "\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/iteration_{itera}/\"\n",
    "        # Create subfolder based on the class name\n",
    "        class_subfolder = class_names[correct_label.item()]\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        \n",
    "        if not os.path.exists(class_output_path):\n",
    "            os.makedirs(class_output_path)\n",
    "\n",
    "        \n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "            # Call different perturbation functions here\n",
    "\n",
    "#             perturbed = create_pixelated_image(x, pixel_size)\n",
    "#             perturbed = create_pixelated_image(x, pixel_size)\n",
    "            perturbed = create_dp_pixelated_image(x, b, m, eps)\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "    \n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "#             annonymized_image.requires_grad = False\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "        \n",
    "\n",
    "    #         # Calculate the output and loss for the anonymized and original images\n",
    "    #         output, _ = calculate_loss(model, annonymized_image, y, criterion)\n",
    "    #         output_original, _ = calculate_loss(model, x.clone(), y, criterion)\n",
    "\n",
    "    #         # Determine the new predicted label for both the anonymized and original images\n",
    "    #         new_label = torch.argmax(output, dim=1)\n",
    "    #         output_original = torch.argmax(output_original, dim=1)\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "# #         save_image(annonymized_image, i, correct_label, iteration_out_path, eps, q)    \n",
    "        else:\n",
    "#             annonymized_image.requires_grad = False\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "#         print(f\"Image {i} processed for q={q}.\")\n",
    "    \n",
    "    # Decrement q for the next iteration\n",
    "#     q -= 3\n",
    "#     iteration_number +=1\n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "#     _,_,our_test_loader = create_data_loader(train_path, new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after the iteration {itera} is {final_acc*100}%\")\n",
    "    \n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db95e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/iteration_14/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a286bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "for itera in range(15,20):\n",
    "\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/iteration_{itera}/\"\n",
    "        # Create subfolder based on the class name\n",
    "        class_subfolder = class_names[correct_label.item()]\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        \n",
    "        if not os.path.exists(class_output_path):\n",
    "            os.makedirs(class_output_path)\n",
    "\n",
    "        \n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "            # Call different perturbation functions here\n",
    "\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "            perturbed = create_pixelated_image(x, pixel_size)\n",
    "\n",
    "#             perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "\n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "#             annonymized_image.requires_grad = False\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "        \n",
    "\n",
    "    #         # Calculate the output and loss for the anonymized and original images\n",
    "    #         output, _ = calculate_loss(model, annonymized_image, y, criterion)\n",
    "    #         output_original, _ = calculate_loss(model, x.clone(), y, criterion)\n",
    "\n",
    "    #         # Determine the new predicted label for both the anonymized and original images\n",
    "    #         new_label = torch.argmax(output, dim=1)\n",
    "    #         output_original = torch.argmax(output_original, dim=1)\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "# #         save_image(annonymized_image, i, correct_label, iteration_out_path, eps, q)    \n",
    "        else:\n",
    "#             annonymized_image.requires_grad = False\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "#         print(f\"Image {i} processed for q={q}.\")\n",
    "    \n",
    "    # Decrement q for the next iteration\n",
    "#     q -= 3\n",
    "#     iteration_number +=1\n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "#     _,_,our_test_loader = create_data_loader(train_path, new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after the iteration {itera} is {final_acc*100}%\")\n",
    "    \n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efda88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/iteration_12/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "for itera in range(13,16):\n",
    "\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/iteration_{itera}/\"\n",
    "        # Create subfolder based on the class name\n",
    "        class_subfolder = class_names[correct_label.item()]\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        \n",
    "        if not os.path.exists(class_output_path):\n",
    "            os.makedirs(class_output_path)\n",
    "\n",
    "        \n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "            # Call different perturbation functions here\n",
    "\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "#             perturbed = create_pixelated_image(x, pixel_size)\n",
    "\n",
    "            perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "\n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "#             annonymized_image.requires_grad = False\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "        \n",
    "\n",
    "    #         # Calculate the output and loss for the anonymized and original images\n",
    "    #         output, _ = calculate_loss(model, annonymized_image, y, criterion)\n",
    "    #         output_original, _ = calculate_loss(model, x.clone(), y, criterion)\n",
    "\n",
    "    #         # Determine the new predicted label for both the anonymized and original images\n",
    "    #         new_label = torch.argmax(output, dim=1)\n",
    "    #         output_original = torch.argmax(output_original, dim=1)\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "# #         save_image(annonymized_image, i, correct_label, iteration_out_path, eps, q)    \n",
    "        else:\n",
    "#             annonymized_image.requires_grad = False\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "#         print(f\"Image {i} processed for q={q}.\")\n",
    "    \n",
    "    # Decrement q for the next iteration\n",
    "#     q -= 3\n",
    "#     iteration_number +=1\n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    _,_,our_test_loader = create_data_loader(train_path, new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after the iteration {itera} is {final_acc*100}%\")\n",
    "    \n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 1\n",
    "iteration_out_path = f\"{output_path}/iteration_15/\"\n",
    "new_test_path = iteration_out_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b764356",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2588999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until all quantile values have been processed\n",
    "for itera in range(16,21):\n",
    "\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "        \n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/iteration_{itera}/\"\n",
    "        # Create subfolder based on the class name\n",
    "        class_subfolder = class_names[correct_label.item()]\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        \n",
    "        if not os.path.exists(class_output_path):\n",
    "            os.makedirs(class_output_path)\n",
    "\n",
    "        \n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "        \n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "        \n",
    "        \n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "\n",
    "            # Call different perturbation functions here\n",
    "\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "#             perturbed = create_pixelated_image(x, pixel_size)\n",
    "\n",
    "            perturbed = create_dp_blurred_image(x, b, m, eps, k, sigma)\n",
    "\n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "#             annonymized_image.requires_grad = False\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "        \n",
    "\n",
    "    #         # Calculate the output and loss for the anonymized and original images\n",
    "    #         output, _ = calculate_loss(model, annonymized_image, y, criterion)\n",
    "    #         output_original, _ = calculate_loss(model, x.clone(), y, criterion)\n",
    "\n",
    "    #         # Determine the new predicted label for both the anonymized and original images\n",
    "    #         new_label = torch.argmax(output, dim=1)\n",
    "    #         output_original = torch.argmax(output_original, dim=1)\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "# #         save_image(annonymized_image, i, correct_label, iteration_out_path, eps, q)    \n",
    "        else:\n",
    "#             annonymized_image.requires_grad = False\n",
    "            save_image_ours(annonymized_image, i, correct_label, class_output_path, eps, q)\n",
    "        \n",
    "#         print(f\"Image {i} processed for q={q}.\")\n",
    "    \n",
    "    # Decrement q for the next iteration\n",
    "#     q -= 3\n",
    "#     iteration_number +=1\n",
    "    print(f\"All images processed for iteration number {itera}.\")\n",
    "    new_test_path = iteration_out_path\n",
    "    _,_,our_test_loader = create_data_loader(train_path, new_test_path, new_batch_size)\n",
    "    # get the list of correctly classified images\n",
    "    final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)\n",
    "    print(f\"The accuracy after the iteration {itera} is {final_acc*100}%\")\n",
    "    \n",
    "print(\"All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0ebf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
