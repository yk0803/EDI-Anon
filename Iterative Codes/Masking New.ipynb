{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from true_classify import *\n",
    "from Utils import *\n",
    "from anonymization_methods import *\n",
    "from datasets import *\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import Counter\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d283082",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing data directories\n",
    "source_path = 'D:/Younas_Work/D2_Final/Original/All FR/train'\n",
    "\n",
    "class_names = [folder for folder in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, folder))]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "file_list = os.listdir(source_path)\n",
    "model_dir = 'Convnext_pretrained_younas.pt'\n",
    "\n",
    "output_path = 'D:/Younas_Work/D2_Final/Anonymized/Expite/Masked_New_2/Face_Recognition'\n",
    "\n",
    "save_roc_dir = 'D:/Younas_Work/D2_Final/Results_Final/ROC/ROC Plots Masked_New/'\n",
    "excel_file_path = 'D:/Younas_Work/D2_Final/Results_Final/Excel_Sheets/Masked_New_2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a64045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.convnext_base(pretrained=True)\n",
    "model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('Convnext_pretrained_younas.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will try a fixed q in each iteration\n",
    "q=99.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, dataset_name, save_dir):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "\n",
    "    # Plot macro-average ROC curve\n",
    "    plt.plot(fpr['micro'], tpr['micro'], color='deeppink', linestyle=':', lw=lw,\n",
    "             label='Macro-average ROC curve (area = {0:0.2f})'.format(roc_auc['micro']))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC for ' + dataset_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, f'ROC_{dataset_name}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e962d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, f1_score, auc, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import xlrd\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "def test_images_classification(original_model, device, local_test_loader, excel_file_path, save_roc_dir):\n",
    "    original_model.eval()\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    correct_examples = []\n",
    "    logits = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    \n",
    "    excel_dir = os.path.dirname(excel_file_path)\n",
    "\n",
    "    # Extract the dataset name from the complete path of local_test_loader\n",
    "    dataset_name = os.path.basename(local_test_loader.dataset.root)\n",
    "\n",
    "    # Extract the complete path of local_test_loader\n",
    "    complete_path = local_test_loader.dataset.root\n",
    "\n",
    "    # Loop over all examples in the test set\n",
    "    for data, target in tqdm(local_test_loader):\n",
    "        counter += 1\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        with torch.no_grad():\n",
    "            output = original_model(data)\n",
    "\n",
    "        final_pred = torch.argmax(output, dim=1)\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "        correct_examples.append(data)\n",
    "        labels.append(target)\n",
    "        logits.append(output)\n",
    "    final_acc = correct / float(len(local_test_loader))\n",
    "\n",
    "    # Calculate the F1 score, precision, and recall\n",
    "    all_logits = torch.cat(logits, dim=0)\n",
    "    all_labels = torch.cat(labels, dim=0)\n",
    "    predicted_labels = torch.argmax(all_logits, dim=1)\n",
    "    f1 = f1_score(all_labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "    precision = precision_score(all_labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "    recall = recall_score(all_labels.cpu(), predicted_labels.cpu(), average='macro')\n",
    "\n",
    "    # Calculate and save the ROC curve data\n",
    "    all_probs = torch.nn.functional.softmax(all_logits, dim=1)\n",
    "    num_classes = all_probs.shape[1]\n",
    "    one_hot_labels = torch.zeros_like(all_probs).scatter_(1, all_labels.view(-1, 1), 1)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(one_hot_labels[:, i].cpu(), all_probs[:, i].cpu())\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Micro-average ROC curve and AUC\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(one_hot_labels.cpu().ravel(), all_probs.cpu().ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Save summary to Excel\n",
    "    if os.path.exists(excel_file_path):\n",
    "        df_summary = pd.read_excel(excel_file_path, sheet_name=\"Summary\", engine=\"openpyxl\")\n",
    "        new_row = {\"Complete Path\": complete_path, \"Accuracy\": final_acc, \"F1 Score\": f1, \"Precision\": precision, \"Recall\": recall, \"AUC\": roc_auc[\"micro\"]}\n",
    "        df_summary = df_summary.append(new_row, ignore_index=True)\n",
    "        df_summary.to_excel(excel_file_path, sheet_name=\"Summary\", index=False)\n",
    "    else:\n",
    "        summary_data = {\"Complete Path\": [complete_path], \"Accuracy\": [final_acc], \"F1 Score\": [f1], \"Precision\": [precision], \"Recall\": [recall], \"AUC\": [roc_auc[\"micro\"]]}\n",
    "        df_summary = pd.DataFrame(summary_data)\n",
    "        df_summary.to_excel(excel_file_path, sheet_name=\"Summary\", index=False)\n",
    "    \n",
    "    # Plot and save the ROC curve\n",
    "    plot_roc_curve(fpr, tpr, roc_auc, dataset_name, save_roc_dir)\n",
    "\n",
    "    # Return the accuracy, F1 score, and an adversarial example\n",
    "    return final_acc, correct_examples, labels, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points_on_image(image, important_pixels_mask, point_size=0.05, point_color=(255, 0, 0)):\n",
    "    # Convert the PyTorch tensor image to a Pillow Image\n",
    "    image_pil = transforms.ToPILImage()(image.cpu().squeeze())\n",
    "\n",
    "    # Create a Pillow drawing object\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    width, height = image_pil.size\n",
    "\n",
    "    # Iterate through each pixel and draw a point if it's an important pixel\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if important_pixels_mask[y, x]:\n",
    "                x0, y0 = x - point_size, y - point_size\n",
    "                x1, y1 = x + point_size, y + point_size\n",
    "                bbox = [(x0, y0), (x1, y1)]\n",
    "\n",
    "                # Draw a point at the important pixel\n",
    "                draw.rectangle(bbox, fill=point_color)\n",
    "\n",
    "    return transforms.ToTensor()(image_pil).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(annonymized_image, i, correct_label, output_path, q):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    ts.save(annonymized_image, os.path.join(output_path, f\"{correct_label.item()}-{i}-q{q}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489af996",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "iteration_out_path = 'D:/Younas_Work/D2_Final/Anonymized/Original/Masked_New_2/Face_Recognition'\n",
    "new_test_path = source_path\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "for itera in range(18,20):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "\n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "\n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "\n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "\n",
    "\n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "            \n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "            \n",
    "            # Call the draw_dots_on_image function\n",
    "            annonymized_image = draw_points_on_image(annonymized_image, optimized_gradients[0, 0, :, :] >= 1, point_size=0.05, point_color=(255, 0, 0))\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, q)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    our_test_loader = create_test_loader(iteration_out_path, batch_size=1)\n",
    "    accuracy, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "    print(f\"\\nAccuracy: {accuracy*100} %\")\n",
    "\n",
    "end_time = time.time()\n",
    "Anon_execution_time = end_time - start_time\n",
    "print(f\"\\nAnon Time: {Anon_execution_time} seconds\")\n",
    "print(f\"All images processed for iteration number {itera}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
