{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a41880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from true_classify import *\n",
    "from Utils import *\n",
    "from anonymization_methods import *\n",
    "from datasets import *\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing data directories\n",
    "train_path = 'F:/younas/FR/Train/'  # Path to the training data directory\n",
    "test_path = 'F:/younas/FR/Test/'  # Path to the testing data directory\n",
    "\n",
    "# test_loader = create_test_loader(test_path, 32)\n",
    "model_dir = 'FR_Adagrad.pt'\n",
    "\n",
    "output_path = \"F:/younas/results_mouth_masked/\"\n",
    "\n",
    "class_names = ['Aaron Judge', 'Aaron Paul', 'Aaron Taylor-Johnson', 'Abigail Breslin', 'Adam Sandler', 'Adele', 'Adriana Lima', 'Adrianne Palicki',\n",
    "               'Adrien Brody', 'Aishwarya Rai Bachchan', 'Akemi Darenogare', 'Akshay Kumar', 'Al Pacino', 'Al Roker', 'Alan Alda',\n",
    "               'Alan Arkin', 'Alan Rickman', 'Albert Brooks', 'Alec Baldwin', 'Alessandra Ambrosio', 'Alex Pettyfer', 'Alexander Skarsgard',\n",
    "               'Alexandra Daddario', 'Alexis Thorpe', 'Ali Larter', 'Alice Eve', 'Alicia Vikander', 'Amanda Bynes', 'Amanda Crew', 'Amanda Peet',\n",
    "               'Amanda Seyfried', 'Amitabh Bachchan', 'Amy Adams', 'Amy Ryan', 'Amy Schumer', 'Analeigh Tipton', 'Anderson Cooper', 'Andie MacDowell',\n",
    "               'Andreea Diaconu', 'Andrew Garfield', 'Andrew Lincoln', 'Anil Kapoor', 'Billy Burke', 'Billy Crudup',\n",
    "               'Billy Crystal', 'Billy Joel', 'Blake Lively', 'Bob Hoskins', 'Bon Jovi', 'Bonnie Hunt', 'Brad Pitt',\n",
    "               'Bradley Cooper', 'Breckin Meyer', 'Brenda Blethyn', 'Brenda Fricker', 'Brendan Fraser', 'Brendan Gleeson',\n",
    "               'Brett Gardner', 'Brian Cox', 'Brie Larson', 'Brielle Biermann', 'Britney Spears', 'Brittany Snow', 'Brody Jenner',\n",
    "               'Bruce Davison', 'Bruce Dern', 'Bruce Lee', 'Deepika Padukone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca9253",
   "metadata": {},
   "outputs": [],
   "source": [
    " # define number of classes\n",
    "num_classes = 68\n",
    "# define the model\n",
    "model = models.resnet18(pretrained= True)\n",
    "# Use most up-to-date weights\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.fc.requires_grad = True\n",
    "#model = models.resnet18(pretrained= True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# load the saved model\n",
    "model.load_state_dict(torch.load(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11739a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of correctly classified images\n",
    "new_batch_size = 1\n",
    "our_test_loader = create_test_loader(test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the eye\n",
    "color = (236,236,28)\n",
    "thickness = -1\n",
    "mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to convert the image to tensor\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_iterative(original_model, device, local_test_loader):\n",
    "    original_model.eval()\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    correct_examples = []\n",
    "    logits = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in local_test_loader:\n",
    "        counter += 1\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # Forward pass the data through the model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = original_model(data)\n",
    "\n",
    "        final_pred = torch.argmax(output, dim=1)\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "        correct_examples.append(data)\n",
    "        labels.append(target)\n",
    "        logits.append(output)\n",
    "    acc2 = correct/float(len(local_test_loader))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850619",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"F:/younas/results_mouth_masked\"\n",
    "side_length = 15  # Initialize the side length\n",
    "mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')\n",
    "celebrities = os.listdir(test_path)\n",
    "total_iterations = 20\n",
    "\n",
    "accuracy_file = open(output_path + '/accuracies.txt', 'w')\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    output_iteration = output_path+'/'+'iteration_'+str(i)\n",
    "    if not os.path.exists(output_iteration):\n",
    "        os.makedirs(output_iteration)\n",
    "\n",
    "    for celebrity in celebrities:\n",
    "        images = os.listdir(test_path+celebrity)\n",
    "        output_celebrity = output_iteration+'/'+ celebrity\n",
    "        if not os.path.exists(output_celebrity):\n",
    "            os.makedirs(output_celebrity)\n",
    "        for image in images:\n",
    "            img_org = cv2.imread(test_path+celebrity+'/'+image)\n",
    "            # Resize the image to 1000 x 1000\n",
    "            temp = cv2.resize(img_org, (1000, 1000), interpolation=cv2.INTER_AREA)\n",
    "            gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "            mouth_rects = mouth_cascade.detectMultiScale(gray, 1.82, 11)\n",
    "            for (x,y,w,h) in mouth_rects:\n",
    "                if x < 100 or x > 10000 or y < 300 or y > 10000:\n",
    "                    print(\"skipped\")\n",
    "                    continue\n",
    "                y = int(y - 0.15*h)\n",
    "                cv2.rectangle(temp, (x,y), (x+w,y+h), (236,236,28), -1) \n",
    "            # Resize it back to 256 x 256\n",
    "            temp = cv2.resize(temp, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(output_celebrity+'/'+image, temp)\n",
    "\n",
    "    our_test_loader = create_test_loader(output_iteration, batch_size=1)\n",
    "    accuracy = test_iterative(model, device, our_test_loader)\n",
    "    print(\"Accuracy at iteration\", i, \":\", accuracy)\n",
    "    print(\"Total increase in Privacy \", i, \"is:\", final_acc - accuracy)\n",
    "\n",
    "    # Save the accuracy to the text file\n",
    "    accuracy_file.write(f\"Accuracy at iteration {i}: {accuracy}\\n\")\n",
    "\n",
    "    # Increase the side_length after each iteration\n",
    "    side_length += 1\n",
    "\n",
    "# Close the accuracy file after all iterations are completed\n",
    "accuracy_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90345016",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"F:/younas/results_mouth_masked\"\n",
    "width = 5  # Initialize the width\n",
    "height = 3  # Initialize the height\n",
    "mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')\n",
    "celebrities = os.listdir(test_path)\n",
    "total_iterations = 20\n",
    "\n",
    "accuracy_file = open(output_path + '/accuracies.txt', 'w')\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    output_iteration = output_path+'/'+'iteration_'+str(i)\n",
    "    if not os.path.exists(output_iteration):\n",
    "        os.makedirs(output_iteration)\n",
    "\n",
    "    for celebrity in celebrities:\n",
    "        images = os.listdir(test_path+celebrity)\n",
    "        output_celebrity = output_iteration+'/'+ celebrity\n",
    "        if not os.path.exists(output_celebrity):\n",
    "            os.makedirs(output_celebrity)\n",
    "        for image in images:\n",
    "            img_org = cv2.imread(test_path+celebrity+'/'+image)\n",
    "            temp = cv2.resize(img_org, (1000, 1000), interpolation=cv2.INTER_AREA)\n",
    "            gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "            mouth_rects = mouth_cascade.detectMultiScale(gray, 1.82, 11)\n",
    "            for (x, y, w, h) in mouth_rects:\n",
    "                if x < 100 or x > 10000 or y < 300 or y > 10000:\n",
    "                    print(\"skipped\")\n",
    "                    continue\n",
    "                y = int(y - 0.15*h)\n",
    "                cv2.rectangle(temp, (x, y), (x+width, y+height), (236, 236, 28), -1)\n",
    "                temp = cv2.resize(temp, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(output_celebrity+'/'+image, temp)\n",
    "                continue  # Break after drawing the first rectangle\n",
    "\n",
    "    our_test_loader = create_test_loader(output_iteration, batch_size=1)\n",
    "    accuracy = test_iterative(model, device, our_test_loader)\n",
    "    print(\"Accuracy at iteration\", i, \":\", accuracy)\n",
    "    print(\"Total increase in Privacy \", i, \"is:\", final_acc - accuracy)\n",
    "\n",
    "    accuracy_file.write(f\"Accuracy at iteration {i}: {accuracy}\\n\")\n",
    "\n",
    "    # Increase the width and height after each iteration\n",
    "    width += 1\n",
    "    height += 1\n",
    "\n",
    "accuracy_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9257d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48030589",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"F:/younas/results_mouth_masked\"\n",
    "width = 5  # Initialize the width\n",
    "height = 3  # Initialize the height\n",
    "mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')\n",
    "celebrities = os.listdir(test_path)\n",
    "total_iterations = 20\n",
    "\n",
    "accuracy_file = open(output_path + '/accuracies.txt', 'w')\n",
    "\n",
    "for i in range(total_iterations):\n",
    "    output_iteration = output_path + '/' + 'iteration_' + str(i)\n",
    "    if not os.path.exists(output_iteration):\n",
    "        os.makedirs(output_iteration)\n",
    "\n",
    "    for celebrity in celebrities:\n",
    "        images = os.listdir(test_path + celebrity)\n",
    "        output_celebrity = output_iteration + '/' + celebrity\n",
    "        if not os.path.exists(output_celebrity):\n",
    "            os.makedirs(output_celebrity)\n",
    "        for image in images:\n",
    "            img_org = cv2.imread(test_path + celebrity + '/' + image)\n",
    "            temp = cv2.resize(img_org, (1000, 1000), interpolation=cv2.INTER_AREA)\n",
    "            gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "            mouth_rects = mouth_cascade.detectMultiScale(gray, 1.82, 11)\n",
    "            if len(mouth_rects) > 0:\n",
    "                # If more than 0 mouths are detected, mask the first one, save the image, and skip the rest\n",
    "                (x, y, w, h) = mouth_rects[0]\n",
    "                y = int(y - 0.15 * h)\n",
    "                cv2.rectangle(temp, (x, y), (x + width, y + height), (236, 236, 28), -1)\n",
    "                cv2.imwrite(output_celebrity + '/' + image, temp)\n",
    "                continue  # Skip the remaining mouths\n",
    "            else:\n",
    "                # If no mouths are detected, save the original image\n",
    "                cv2.imwrite(output_celebrity + '/' + image, img_org)\n",
    "\n",
    "            temp = cv2.resize(temp, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    our_test_loader = create_test_loader(output_iteration, batch_size=1)\n",
    "    accuracy = test_iterative(model, device, our_test_loader)\n",
    "    print(\"Accuracy at iteration\", i, \":\", accuracy)\n",
    "    print(\"Total increase in Privacy \", i, \"is:\", final_acc - accuracy)\n",
    "\n",
    "    accuracy_file.write(f\"Accuracy at iteration {i}: {accuracy}\\n\")\n",
    "\n",
    "    # Increase the width and height after each iteration\n",
    "    width += 1\n",
    "    height += 1\n",
    "\n",
    "accuracy_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d4544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598aab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011ac39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01156ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919afb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ff786",
   "metadata": {},
   "outputs": [],
   "source": [
    "                eyes = eye_cascade.detectMultiScale(img_org, scaleFactor=1.2, minNeighbors=4)\n",
    "                for (x, y, w, h) in eyes:\n",
    "                    if x< 18:\n",
    "                        print(\"skipped_x1\")\n",
    "                        continue\n",
    "                    if x> 200:\n",
    "                        print(\"skipped_x2\")\n",
    "                        continue\n",
    "                    if y< 10:\n",
    "                        print(\"skipped_y1\")\n",
    "                        continue\n",
    "                    if y> 220:\n",
    "                        print(\"skipped_y2\")\n",
    "                        continue\n",
    "                    temp = cv2.circle(img_org, (int((x + w / 2)), int((y + h / 2))), radius, color, thickness)\n",
    "                    cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "                    cv2.imwrite(output_celebrity+'/'+image, temp)\n",
    "            else:\n",
    "                cv2.imwrite(output_celebrity+'/'+image, img_org)\n",
    "    \n",
    "    \n",
    "    our_test_loader = create_test_loader(output_iteration, batch_size=1)\n",
    "    accuracy = test_iterative(model, device, our_test_loader)\n",
    "    print(\"Accuracy at iteration\", i, \":\", accuracy)\n",
    "    print(\"Total increase in Privacy \", i, \"is:\", final_acc - accuracy)\n",
    "    # Save the accuracy to the text file\n",
    "    accuracy_file.write(f\"Accuracy at iteration {i}: {accuracy}\\n\")\n",
    "    \n",
    "    radius +=1\n",
    "accuracy_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720837d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"F:/younas/results_eye_masked\"\n",
    "radius =30  # Initialize the radius\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "celebrities = os.listdir(test_path)\n",
    "for i in range(2):\n",
    "    output_iteration = output_path+'/'+'iteration_'+str(i)\n",
    "    if not os.path.exists(output_iteration):\n",
    "        os.makedirs(output_iteration)\n",
    "    \n",
    "    for celebrity in celebrities:\n",
    "        images = os.listdir(test_path+celebrity)\n",
    "        output_celebrity = output_iteration+'/'+ celebrity\n",
    "        if not os.path.exists(output_celebrity):\n",
    "            os.makedirs(output_celebrity)\n",
    "        for image in images:\n",
    "            img_org = cv2.imread(test_path+celebrity+'/'+image)\n",
    "            img = cv2.cvtColor(img_org, cv2.COLOR_BGR2RGB)\n",
    "            transform = transforms.ToTensor()\n",
    "            tens_img = transform(img)\n",
    "            tens_img = tens_img.to(device)\n",
    "            tens_img = tens_img.unsqueeze(0)\n",
    "            for place in range(len(class_names)):\n",
    "                if class_names[place] == celebrity:\n",
    "                    label = place\n",
    "                    \n",
    "            label = torch.tensor(label).unsqueeze(0)\n",
    "            label = label.to(device)\n",
    "            output, loss = calculate_loss(model, tens_img, label, criterion)\n",
    "            \n",
    "            if output == label:\n",
    "                eyes = eye_cascade.detectMultiScale(img_org, scaleFactor=1.2, minNeighbors=4)\n",
    "                for (x, y, w, h) in eyes:\n",
    "#                     if x< 50:\n",
    "#                         print(\"skipped_x1\")\n",
    "#                         continue\n",
    "#                     if x> 192:\n",
    "#                         print(\"skipped_x2\")\n",
    "#                         continue\n",
    "#                     if y< 40:\n",
    "#                         print(\"skipped_y1\")\n",
    "#                         continue\n",
    "#                     if y> 220:\n",
    "#                         print(\"skipped_y2\")\n",
    "#                         continue\n",
    "                    temp = cv2.circle(img_org, (int((x + w / 2)), int((y + h / 2))), radius, color, thickness)\n",
    "                    cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "                    cv2.imwrite(output_celebrity+'/'+image, temp)\n",
    "            cv2.imwrite(output_celebrity+'/'+image, img_org)\n",
    "            radius +=2\n",
    "                \n",
    "\n",
    "                    \n",
    "                    \n",
    "#             annonymized_image = mask_eyes(x, eye_cascade, radius, color, thickness)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
