{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, f1_score, auc, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from true_classify import *\n",
    "from Utils import *\n",
    "from anonymization_methods import *\n",
    "from datasets import *\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import Counter\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import openpyxl\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d283082",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing data directories\n",
    "source_path = 'F:/Original/All FR/train'\n",
    "\n",
    "class_names = [folder for folder in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, folder))]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "file_list = os.listdir(source_path)\n",
    "model_dir = 'Convnext_pretrained_younas.pt'\n",
    "\n",
    "output_path = 'F:/Anonymized/EDI/Pix/Face_Recognition'\n",
    "\n",
    "save_roc_dir = 'F:/Results_Final/ROC/ROC Plots Mouth_Masked/'\n",
    "excel_file_path = 'F:/Results_Final/Excel_Sheets/EDI_All_FR_Results.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a64045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e3817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.convnext_base(pretrained=True)\n",
    "model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('Convnext_pretrained_younas.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will try a fixed q in each iteration\n",
    "q=95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50893a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Parameter values\n",
    "\n",
    "#For Simple Blur\n",
    "blur_kernel_size = 40\n",
    "\n",
    "#For Simple Pixelate\n",
    "pixel_size = 20\n",
    "\n",
    "\n",
    "#for DP\n",
    "#create_dp_pixelated_image(x, b, m, eps)\n",
    "# we need x which is the input image, b which is the block size, the higher (after a certain value) the more noise,\n",
    "#lower before a certain value does not automatically reduce noise if a very small eps is used\n",
    "\n",
    "#Larger m more neighbors disnguishability hence more noise, lesser eps more noise\n",
    "\n",
    "#For DP Pix\n",
    "b = 32\n",
    "m = 16\n",
    "eps = 100\n",
    "\n",
    "\n",
    "#create_dp_blurred_image(x, b0, m, eps, k, sigma)\n",
    "# x, m, and eps are the same\n",
    "#whereas, we need to use a different b (b0) for pixelation and DP pixelation, which would reduce the noise and just pixelate it\n",
    "#K is kernel size for gaussian blur. Height and width of the Gaussian kernel\n",
    "#SD of Gaussian blur. Larger sigma means more blurring, the paper did not use this, so we are using 0, in both cases\n",
    "\n",
    "b0 = 32 #recommended half of the original b\n",
    "k = 9\n",
    "sigma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa763637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimize_gradients(gradients, q):\n",
    "#     grad = gradients.cpu().squeeze().data.detach().cpu().numpy()\n",
    "#     q_local = get_quartiles(grad, q)\n",
    "#     idx = np.where(grad < q_local)\n",
    "#     total = len(idx[2])+len(idx[1])+len(idx[2])\n",
    "#     print(total)\n",
    "#     idx_up = np.where(grad >= q_local)\n",
    "#     grad[idx] = 0\n",
    "#     grad[idx_up] = 1\n",
    "#     grad = np.transpose(grad, (1, 2, 0))\n",
    "#     trans1 = transforms.ToTensor()\n",
    "#     grad = trans1(grad)\n",
    "#     grad = torch.unsqueeze(grad, 0)\n",
    "#     return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1f787",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "new_batch_size = 1\n",
    "new_test_path = 'F:/Anonymized/EDI/Pix/Face_Recognition/Iteration_68'\n",
    "our_test_loader = create_test_loader(new_test_path, new_batch_size)\n",
    "final_acc, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "prev_acc = final_acc\n",
    "print(prev_acc*100)\n",
    "\n",
    "end_time = time.time()\n",
    "acc_time = end_time - start_time\n",
    "print(f\"\\nAcc execution time: {acc_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e26732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# If the number of iterations crashed your system, try the iterations in batches (batch of 5)\n",
    "for itera in range(69,72):\n",
    "    # Iterate through all correct examples\n",
    "    for i in range(len(correct_examples)):\n",
    "        x, correct_label, prediction = correct_examples[i], labels[i], logits[i]\n",
    "        y = get_second_largest(logits[i])\n",
    "        y = torch.tensor([y]).to(device)\n",
    "\n",
    "        # Create the output directory for this iteration\n",
    "        iteration_out_path = f\"{output_path}/Iteration_{itera}/\"\n",
    "\n",
    "        class_label = labels[i]\n",
    "        class_subfolder = class_names[class_label]            \n",
    "\n",
    "        # Create subfolder based on the class name\n",
    "    #         class_subfolder = class_names[correct_label.item()]\n",
    "\n",
    "        class_output_path = os.path.join(iteration_out_path, class_subfolder)\n",
    "        os.makedirs(class_output_path, exist_ok=True)\n",
    "\n",
    "        # Clone the original image and enable gradient computation\n",
    "        annonymized_image = x.clone()\n",
    "        annonymized_image.requires_grad = True\n",
    "\n",
    "        # Calculate the loss based on the model, image, and criterion\n",
    "        output, loss = calculate_loss(model, annonymized_image, y, criterion)\n",
    "\n",
    "\n",
    "        if(output.item() == labels[i].item()):\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            img_grad = annonymized_image.grad.data\n",
    "            \n",
    "#             perturbed = create_dp_blurred_image(x, b0, m, eps, k, sigma)\n",
    "#             perturbed = create_dp_pixelated_image(x, b, m, eps)\n",
    "\n",
    "    # Call different perturbation functions here\n",
    "#             perturbed = create_blurred_image(x, blur_kernel_size)\n",
    "            perturbed = create_pixelated_image(x, pixel_size)\n",
    "#             perturbed = create_dp_blurred_image(x, b0, m, eps, k, sigma)\n",
    "            \n",
    "\n",
    "\n",
    "            # Calculate noise based on the original and perturbed images\n",
    "            noise = calculate_noise(x, perturbed, device)\n",
    "\n",
    "            # Optimize the gradients using the quantile value (q)\n",
    "            optimized_gradients = optimize_gradients(img_grad, q)\n",
    "            optimized_gradients = optimized_gradients.to(device)\n",
    "\n",
    "            # Update the noise using optimized gradients\n",
    "            updated_noise = noise * optimized_gradients\n",
    "\n",
    "            # Create the anonymized image by subtracting/adding the updated noise from the original image\n",
    "            annonymized_image = annonymized_image - updated_noise\n",
    "\n",
    "            # Save the anonymized image to the output directory\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, 100-q)  \n",
    "        else:\n",
    "            save_image(annonymized_image, i, correct_label, class_output_path, pixel_size, 100-q)\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    our_test_loader = create_test_loader(iteration_out_path, batch_size=1)\n",
    "    accuracy, correct_examples, labels, logits = test_images_classification(model, device, our_test_loader, excel_file_path, save_roc_dir)\n",
    "    print(f\"\\nAccuracy: {accuracy*100} %\")\n",
    "\n",
    "end_time = time.time()\n",
    "Anon_execution_time = end_time - start_time\n",
    "print(f\"\\nAnon Time: {Anon_execution_time} seconds\")\n",
    "print(f\"All images processed for iteration number {itera}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab992f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bbad163",
   "metadata": {},
   "source": [
    "Pix with BS 20\n",
    "\n",
    "Accuracy: 49.72692517749863 %\n",
    "\n",
    "Anon Time: 1655.7662649154663 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Accuracy: 21.545603495357728 %\n",
    "\n",
    "Anon Time: 1424.089788198471 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 12.424904423812125 %\n",
    "\n",
    "Anon Time: 1391.1427669525146 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 8.083014746040416 %\n",
    "\n",
    "Anon Time: 1365.8819558620453 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 6.1714909885308575 %\n",
    "\n",
    "Anon Time: 1418.8250737190247 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 5.488803932277444 %\n",
    "\n",
    "Anon Time: 1422.5699796676636 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 4.478427089022392 %\n",
    "\n",
    "Anon Time: 1402.0778336524963 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 3.9595849262697977 %\n",
    "\n",
    "Anon Time: 1411.1460461616516 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 3.46805024576734 %\n",
    "\n",
    "Anon Time: 1434.4932234287262 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 2.9219006007646096 %\n",
    "\n",
    "Anon Time: 1422.658697128296 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "Accuracy: 2.184598580010923 %\n",
    "\n",
    "Anon Time: 1448.3849272727966 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "Accuracy: 2.3757509557618786 %\n",
    "\n",
    "Anon Time: 1441.4864106178284 seconds\n",
    "All images processed for iteration number 35.\n",
    "\n",
    "Accuracy: 2.3211359912616056 %\n",
    "\n",
    "Anon Time: 1459.0054905414581 seconds\n",
    "All images processed for iteration number 38.\n",
    "\n",
    "Accuracy: 2.457673402512288 %\n",
    "\n",
    "Anon Time: 1429.6848278045654 seconds\n",
    "All images processed for iteration number 41.\n",
    "\n",
    "Accuracy: 2.020753686510104 %\n",
    "\n",
    "Anon Time: 1447.451754808426 seconds\n",
    "All images processed for iteration number 44.\n",
    "\n",
    "Accuracy: 1.8569087930092845 %\n",
    "\n",
    "Anon Time: 1438.3847453594208 seconds\n",
    "All images processed for iteration number 47.\n",
    "\n",
    "Accuracy: 1.774986346258875 %\n",
    "\n",
    "Anon Time: 1462.4705891609192 seconds\n",
    "All images processed for iteration number 50.\n",
    "\n",
    "Accuracy: 1.5019115237575096 %\n",
    "\n",
    "Anon Time: 1414.225788116455 seconds\n",
    "All images processed for iteration number 53.\n",
    "\n",
    "Accuracy: 1.3926815947569635 %\n",
    "\n",
    "Anon Time: 1408.6027116775513 seconds\n",
    "All images processed for iteration number 56.\n",
    "\n",
    "Accuracy: 1.2834516657564172 %\n",
    "\n",
    "Anon Time: 1445.8384294509888 seconds\n",
    "All images processed for iteration number 59.\n",
    "\n",
    "Accuracy: 1.2561441835062808 %\n",
    "\n",
    "Anon Time: 1410.9528658390045 seconds\n",
    "All images processed for iteration number 62.\n",
    "\n",
    "Accuracy: 1.3107591480065537 %\n",
    "\n",
    "Anon Time: 1408.3483335971832 seconds\n",
    "All images processed for iteration number 65.\n",
    "\n",
    "Accuracy: 1.1469142545057347 %\n",
    "\n",
    "Anon Time: 1429.120777606964 seconds\n",
    "All images processed for iteration number 68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b74075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b0be379",
   "metadata": {},
   "source": [
    "Pix with BS 15\n",
    "\n",
    "Accuracy: 53.54997269251774 %\n",
    "\n",
    "Anon Time: 1641.5903458595276 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "\n",
    "Accuracy: 24.822501365374112 %\n",
    "\n",
    "Anon Time: 1475.218293428421 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 14.44565811032223 %\n",
    "\n",
    "Anon Time: 1510.5347275733948 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 9.503003823047514 %\n",
    "\n",
    "Anon Time: 1438.1695866584778 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 8.301474604041507 %\n",
    "\n",
    "Anon Time: 1434.8055348396301 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "\n",
    "Accuracy: 7.045330420535227 %\n",
    "\n",
    "Anon Time: 1665.0537581443787 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 7.0999453850355 %\n",
    "\n",
    "Anon Time: 1404.3785421848297 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 5.516111414527581 %\n",
    "\n",
    "Anon Time: 1659.36869931221 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 5.133806663025669 %\n",
    "\n",
    "Anon Time: 1733.8373816013336 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 4.423812124522119 %\n",
    "\n",
    "Anon Time: 1804.1841077804565 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "Accuracy: 3.6865101037684327 %\n",
    "\n",
    "Anon Time: 1443.3368220329285 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "Accuracy: 3.9595849262697977 %\n",
    "\n",
    "Anon Time: 1430.9130320549011 seconds\n",
    "All images processed for iteration number 35.\n",
    "\n",
    "\n",
    "Accuracy: 3.358820316766794 %\n",
    "\n",
    "Anon Time: 1452.633713722229 seconds\n",
    "All images processed for iteration number 38.\n",
    "\n",
    "Accuracy: 3.1676679410158384 %\n",
    "\n",
    "Anon Time: 1446.1268725395203 seconds\n",
    "All images processed for iteration number 41.\n",
    "\n",
    "Accuracy: 3.003823047515019 %\n",
    "\n",
    "Anon Time: 1418.2089540958405 seconds\n",
    "All images processed for iteration number 44.\n",
    "\n",
    "Accuracy: 2.4030584380120152 %\n",
    "\n",
    "Anon Time: 1415.6000699996948 seconds\n",
    "All images processed for iteration number 47.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7477e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d625a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fe99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e473297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fb6c82c",
   "metadata": {},
   "source": [
    "Anon Time: 1705.145141839981 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "\n",
    "Accuracy: 48.41616602949208 %\n",
    "\n",
    "Anon Time: 1606.145141839981 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 30.638995084653192 %\n",
    "\n",
    "Anon Time: 1528.3995959758759 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 19.79792463134899 %\n",
    "\n",
    "Anon Time: 1475.8778047561646 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "missed one\n",
    "\n",
    "Accuracy: 8.137629710540688 %\n",
    "\n",
    "Anon Time: 1445.648427248001 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 5.953031130529765 %\n",
    "\n",
    "Anon Time: 1435.8225164413452 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 4.560349535772802 %\n",
    "\n",
    "Anon Time: 1480.136723279953 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 3.3042053522665213 %\n",
    "\n",
    "Anon Time: 1453.2622804641724 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 2.7307482250136537 %\n",
    "\n",
    "Anon Time: 1471.7750742435455 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "Accuracy: 2.2938285090114694 %\n",
    "\n",
    "Anon Time: 1456.1509764194489 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "Accuracy: 1.774986346258875 %\n",
    "\n",
    "Anon Time: 1460.2456846237183 seconds\n",
    "All images processed for iteration number 35.\n",
    "\n",
    "\n",
    "Accuracy: 1.5292190060076463 %\n",
    "\n",
    "Anon Time: 1433.1150388717651 seconds\n",
    "All images processed for iteration number 38.\n",
    "\n",
    "\n",
    "Accuracy: 1.1742217367558712 %\n",
    "\n",
    "Anon Time: 1447.6232042312622 seconds\n",
    "All images processed for iteration number 41.\n",
    "\n",
    "Accuracy: 0.8738394320043691 %\n",
    "\n",
    "Anon Time: 1438.8332269191742 seconds\n",
    "All images processed for iteration number 44."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40733f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75590cfd",
   "metadata": {},
   "source": [
    "Accuracy: 98.68924085199345 %\n",
    "\n",
    "Anon Time: 1694.9894626140594 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Accuracy: 91.88967777170944 %\n",
    "\n",
    "Anon Time: 1662.7095577716827 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 80.44784270890224 %\n",
    "\n",
    "Anon Time: 1647.600581407547 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 67.47678864008738 %\n",
    "\n",
    "Anon Time: 1579.717096567154 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "\n",
    "Accuracy: 54.94265428727472 %\n",
    "\n",
    "Anon Time: 1555.2830095291138 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 44.15619879847078 %\n",
    "\n",
    "Anon Time: 1508.8828449249268 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 35.28126706717641 %\n",
    "\n",
    "Anon Time: 1478.4752361774445 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 27.826324412889132 %\n",
    "\n",
    "Anon Time: 1418.6979348659515 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77f1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3ca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a4780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0faac06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d24d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1620265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb40d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d642bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080b11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9681d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d3d2db1",
   "metadata": {},
   "source": [
    "Accuracy: 97.21463681048607 %\n",
    "\n",
    "Anon Time: 1642.7934617996216 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 92.32659748771164 %\n",
    "\n",
    "Anon Time: 1667.3688173294067 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 85.14472965592572 %\n",
    "\n",
    "Anon Time: 1639.1201922893524 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 76.54287274713272 %\n",
    "\n",
    "Anon Time: 1595.39142203331 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 67.77717094483889 %\n",
    "\n",
    "Anon Time: 1615.782452583313 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 59.14800655379574 %\n",
    "\n",
    "Anon Time: 1505.7750158309937 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 51.88421627525942 %\n",
    "\n",
    "Anon Time: 1514.0334422588348 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 44.72965592572365 %\n",
    "\n",
    "Anon Time: 1507.9489579200745 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 38.31239759694156 %\n",
    "\n",
    "Anon Time: 1482.005931377411 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "Accuracy: 32.41398143091207 %\n",
    "\n",
    "Anon Time: 1462.3578870296478 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "Accuracy: 27.74440196613872 %\n",
    "\n",
    "Anon Time: 1439.2906155586243 seconds\n",
    "All images processed for iteration number 35.\n",
    "\n",
    "Accuracy: 23.75750955761879 %\n",
    "\n",
    "Anon Time: 1410.6026022434235 seconds\n",
    "All images processed for iteration number 38.\n",
    "\n",
    "Accuracy: 20.562534134352813 %\n",
    "\n",
    "Anon Time: 1410.4384293556213 seconds\n",
    "All images processed for iteration number 41.\n",
    "\n",
    "Accuracy: 17.149098853085746 %\n",
    "\n",
    "Anon Time: 1449.3562803268433 seconds\n",
    "All images processed for iteration number 44.\n",
    "\n",
    "\n",
    "Accuracy: 14.74604041507373 %\n",
    "\n",
    "Anon Time: 1400.3454177379608 seconds\n",
    "All images processed for iteration number 47.\n",
    "\n",
    "Accuracy: 13.462588749317314 %\n",
    "\n",
    "Anon Time: 411.9242467880249 seconds\n",
    "All images processed for iteration number 48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154f0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd830e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff243b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da84fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ec779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5397d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a0f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d690526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067028c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9f3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a78f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3beed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516ba5f9",
   "metadata": {},
   "source": [
    "Accuracy: 98.03386127799017 %\n",
    "\n",
    "Anon Time: 1835.5235884189606 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Accuracy: 88.72200983069362 %\n",
    "\n",
    "Anon Time: 1732.3147201538086 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 72.61059530311306 %\n",
    "\n",
    "Anon Time: 1725.6176888942719 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 56.690333151283454 %\n",
    "\n",
    "Anon Time: 2178.500242471695 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 43.96504642271983 %\n",
    "\n",
    "Anon Time: 1521.6785006523132 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 33.451665756417256 %\n",
    "\n",
    "Anon Time: 1441.194378376007 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 26.788640087383943 %\n",
    "\n",
    "Anon Time: 1729.4973013401031 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 20.75368651010377 %\n",
    "\n",
    "Anon Time: 1549.8581056594849 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 16.193336974330965 %\n",
    "\n",
    "Anon Time: 1449.5039274692535 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6150ac",
   "metadata": {},
   "source": [
    "Blur\n",
    "\n",
    "Accuracy: 94.6204259967231 %\n",
    "\n",
    "Anon Time: 1670.2861230373383 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Accuracy: 76.59748771163298 %\n",
    "\n",
    "Anon Time: 1605.4640808105469 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 54.833424358274165 %\n",
    "\n",
    "Anon Time: 1535.8226952552795 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 36.6193336974331 %\n",
    "\n",
    "Anon Time: 1472.0906715393066 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 25.53249590387766 %\n",
    "\n",
    "Anon Time: 1443.523648262024 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 17.476788640087385 %\n",
    "\n",
    "Anon Time: 1416.9053795337677 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 12.479519388312397 %\n",
    "\n",
    "Anon Time: 1397.1633858680725 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "iteration 19 does it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffffc2",
   "metadata": {},
   "source": [
    "Pix\n",
    "\n",
    "Accuracy: 68.37793555434189 %\n",
    "\n",
    "Anon Time: 1653.597927570343 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Accuracy: 37.38394320043692 %\n",
    "\n",
    "Anon Time: 1471.2509217262268 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 25.805570726379027 %\n",
    "\n",
    "Anon Time: 1417.1616575717926 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "LAST 3 ARE MISSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c76646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e079301",
   "metadata": {},
   "source": [
    "DP Blur\n",
    "\n",
    "Accuracy: 60.26761332605134 %\n",
    "\n",
    "Anon Time: 1795.316531419754 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "missed one here\n",
    "\n",
    "Accuracy: 14.145275805570726 %\n",
    "\n",
    "Anon Time: 1477.6396446228027 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 7.755324959038777 %\n",
    "\n",
    "Anon Time: 1404.6242561340332 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 5.652648825778264 %\n",
    "\n",
    "Anon Time: 1392.6372911930084 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 3.6865101037684327 %\n",
    "\n",
    "Anon Time: 1398.7609040737152 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 3.2495903877662475 %\n",
    "\n",
    "Anon Time: 1420.8439662456512 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 2.2665210267613327 %\n",
    "\n",
    "Anon Time: 1436.6383368968964 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 2.020753686510104 %\n",
    "\n",
    "Anon Time: 1427.342900276184 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 1.9388312397596943 %\n",
    "\n",
    "Anon Time: 1448.3249609470367 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "\n",
    "Accuracy: 1.7476788640087382 %\n",
    "\n",
    "Anon Time: 1415.4095394611359 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "\n",
    "Accuracy: 1.6111414527580556 %\n",
    "\n",
    "Anon Time: 1442.3765335083008 seconds\n",
    "All images processed for iteration number 35.\n",
    "\n",
    "\n",
    "Accuracy: 1.3107591480065537 %\n",
    "\n",
    "Anon Time: 1449.046518087387 seconds\n",
    "All images processed for iteration number 38.\n",
    "\n",
    "\n",
    "Accuracy: 0.9830693610049154 %\n",
    "\n",
    "39 is also 0.98\n",
    "\n",
    "Anon Time: 1450.2956638336182 seconds\n",
    "All images processed for iteration number 41.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff592eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c725560",
   "metadata": {},
   "source": [
    "DP Pix\n",
    "\n",
    "Plus 100 seconds\n",
    "\n",
    "Anon Time: 1693.9437828063965 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Time for 3, 4 and 5 needs to be done again, or manually inferenced\n",
    "\n",
    "Anon Time: 1442.4036922454834 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Anon Time: 1428.0455169677734 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Anon Time: 1439.1756038665771 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Anon Time: 1427.472996711731 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 3.194975423265975 %\n",
    "\n",
    "Anon Time: 1441.0913925170898 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 2.4030584380120152 %\n",
    "\n",
    "Anon Time: 1443.2411394119263 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 2.2938285090114694 %\n",
    "\n",
    "Anon Time: 1406.3963334560394 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "Accuracy: 2.1572910977607864 %\n",
    "\n",
    "Anon Time: 1431.9816498756409 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "Iteration 30 achieves it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca0888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b2b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3949dd0",
   "metadata": {},
   "source": [
    "Blur\n",
    "\n",
    "Accuracy: 99.64500273074822 %\n",
    "\n",
    "Anon Time: 1677.3597085475922 seconds\n",
    "All images processed for iteration number 2.\n",
    "\n",
    "Accuracy: 97.21463681048607 %\n",
    "\n",
    "Anon Time: 1629.5300686359406 seconds\n",
    "All images processed for iteration number 5.\n",
    "\n",
    "Accuracy: 92.32659748771164 %\n",
    "\n",
    "Anon Time: 1660.037616968155 seconds\n",
    "All images processed for iteration number 8.\n",
    "\n",
    "Accuracy: 85.14472965592572 %\n",
    "\n",
    "Anon Time: 1583.4810528755188 seconds\n",
    "All images processed for iteration number 11.\n",
    "\n",
    "Accuracy: 76.54287274713272 %\n",
    "\n",
    "Anon Time: 1589.7678318023682 seconds\n",
    "All images processed for iteration number 14.\n",
    "\n",
    "Accuracy: 67.77717094483889 %\n",
    "\n",
    "Anon Time: 1572.1026682853699 seconds\n",
    "All images processed for iteration number 17.\n",
    "\n",
    "Accuracy: 59.14800655379574 %\n",
    "\n",
    "Anon Time: 1499.0802021026611 seconds\n",
    "All images processed for iteration number 20.\n",
    "\n",
    "Accuracy: 51.88421627525942 %\n",
    "\n",
    "Anon Time: 1498.8100275993347 seconds\n",
    "All images processed for iteration number 23.\n",
    "\n",
    "Accuracy: 44.72965592572365 %\n",
    "\n",
    "Anon Time: 1485.097520828247 seconds\n",
    "All images processed for iteration number 26.\n",
    "\n",
    "Accuracy: 38.31239759694156 %\n",
    "\n",
    "Anon Time: 1472.33660197258 seconds\n",
    "All images processed for iteration number 29.\n",
    "\n",
    "Accuracy: 32.41398143091207 %\n",
    "\n",
    "Anon Time: 1453.926073551178 seconds\n",
    "All images processed for iteration number 32.\n",
    "\n",
    "Accuracy: 27.74440196613872 %\n",
    "\n",
    "Anon Time: 1436.5961413383484 seconds\n",
    "All images processed for iteration number 35.\n",
    "\n",
    "Accuracy: 23.75750955761879 %\n",
    "\n",
    "Anon Time: 1395.828239440918 seconds\n",
    "All images processed for iteration number 38.\n",
    "\n",
    "Accuracy: 20.562534134352813 %\n",
    "\n",
    "Anon Time: 1399.549635887146 seconds\n",
    "All images processed for iteration number 41.\n",
    "\n",
    "Iteration 43\n",
    "\n",
    "Accuracy: 18.405243036592026 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
